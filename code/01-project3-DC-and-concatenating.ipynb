{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cb92c54e",
   "metadata": {},
   "source": [
    "### This is the 2nd codefile of the project, after data-gathering using PRAWs\n",
    "#### See ./000-reddit-pulls.py\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "930218a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import numpy as np \n",
    "    #maybe\n",
    "    #tim always does (for .arange() ??)\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "from os import listdir\n",
    "from os.path import isfile, join"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "653a86fe",
   "metadata": {},
   "source": [
    "### My Subreddits:\n",
    "* r/explainlikeimfive (referred to as sub1 below)\n",
    "* r/nostupidquestions (referred to as sub2 below)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "103d7151-cf2e-47cb-82c2-578faa763888",
   "metadata": {},
   "outputs": [],
   "source": [
    "#2 - \n",
    "#read in the saved, large quantity of csv's for each chosen subreddit, \n",
    "#to get 2 separate ENORMOUS DFs (1 per subreddit)\n",
    "\n",
    "#Current efficiency issue:\n",
    "#for future refactoring!\n",
    "#on 2nd+ runs, this will re-slurp the \"nodupes.csv\" files that I create later\n",
    "\n",
    "mypath = \"../data/\"\n",
    "many_files = [mypath+f for f in listdir(mypath) if isfile(join(mypath, f))]\n",
    "    #attrib\n",
    "    #https://stackoverflow.com/questions/3207219/how-do-i-list-all-files-of-a-directory\n",
    "\n",
    "#read in & create dirty dataframe for sub1\n",
    "sub1_files = [g for g in many_files if \"sub1\" in g]\n",
    "for file in sub1_files:\n",
    "    #attrib\n",
    "    #https://mungingdata.com/pandas/read-multiple-csv-pandas-dataframe/\n",
    "    df_sub1_long = pd.concat((pd.read_csv(i) for i in sub1_files))        \n",
    "   \n",
    "#read in & create dirty dataframe for sub1 \n",
    "sub2_files = [h for h in many_files if \"sub2\" in h]\n",
    "for file in sub2_files:\n",
    "    #attrib\n",
    "    #https://mungingdata.com/pandas/read-multiple-csv-pandas-dataframe/\n",
    "    df_sub2_long = pd.concat((pd.read_csv(j) for j in sub2_files))        \n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a4a9119e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10962, 6)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sub1_long.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ea22a4f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>created_utc</th>\n",
       "      <th>title</th>\n",
       "      <th>self_text</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>Unnamed: 0.1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1.697390e+09</td>\n",
       "      <td>eli5 could people from the last century compre...</td>\n",
       "      <td>Lets say someone in 1990 plays some Super Mari...</td>\n",
       "      <td>explainlikeimfive</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1.697390e+09</td>\n",
       "      <td>Eli5 Home EV charging</td>\n",
       "      <td>Don’t know anything about EV charging\\n\\nWhat ...</td>\n",
       "      <td>explainlikeimfive</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1.697390e+09</td>\n",
       "      <td>ELI5: why are we potentially able to hold our ...</td>\n",
       "      <td>I understand that it's the lack of oxygen that...</td>\n",
       "      <td>explainlikeimfive</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1.697389e+09</td>\n",
       "      <td>ELI5: Acquiring my car’s title registration?</td>\n",
       "      <td>Hey everyone, first time truly posting so bear...</td>\n",
       "      <td>explainlikeimfive</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1.697389e+09</td>\n",
       "      <td>eli5- engine &amp; cabin air filters</td>\n",
       "      <td>ELI5 - why does the auto mechanic always try t...</td>\n",
       "      <td>explainlikeimfive</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0   created_utc  \\\n",
       "0           0  1.697390e+09   \n",
       "1           1  1.697390e+09   \n",
       "2           2  1.697390e+09   \n",
       "3           3  1.697389e+09   \n",
       "4           4  1.697389e+09   \n",
       "\n",
       "                                               title  \\\n",
       "0  eli5 could people from the last century compre...   \n",
       "1                              Eli5 Home EV charging   \n",
       "2  ELI5: why are we potentially able to hold our ...   \n",
       "3       ELI5: Acquiring my car’s title registration?   \n",
       "4                   eli5- engine & cabin air filters   \n",
       "\n",
       "                                           self_text          subreddit  \\\n",
       "0  Lets say someone in 1990 plays some Super Mari...  explainlikeimfive   \n",
       "1  Don’t know anything about EV charging\\n\\nWhat ...  explainlikeimfive   \n",
       "2  I understand that it's the lack of oxygen that...  explainlikeimfive   \n",
       "3  Hey everyone, first time truly posting so bear...  explainlikeimfive   \n",
       "4  ELI5 - why does the auto mechanic always try t...  explainlikeimfive   \n",
       "\n",
       "   Unnamed: 0.1  \n",
       "0           NaN  \n",
       "1           NaN  \n",
       "2           NaN  \n",
       "3           NaN  \n",
       "4           NaN  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sub1_long.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fe710c91",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6905, 6)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sub2_long.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a9197060",
   "metadata": {},
   "outputs": [],
   "source": [
    "#3.0 - remove the empty posts, just in case they sneaked in thru the pull code's culling\n",
    "df_sub1_long = df_sub1_long[ df_sub1_long['self_text'] != '']\n",
    "df_sub2_long = df_sub2_long[ df_sub2_long['self_text'] != '']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e8280f38",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10962, 6)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#which they didn't\n",
    "df_sub1_long.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3df8cd87",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6905, 6)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sub2_long.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f7f33e1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#3.1 remove duplicates from both subreddits' data\n",
    "    #\"\" TIP: You can use the created_utc attribute of a post to keep track of the timestamp and ensure non-overlapping pulls. The created_utc attribute represents the post's creation time in UTC.\"\"\n",
    "    #info this might have saved me the de-duping work\n",
    "\n",
    "#attrib: Rafi for syntax of dropping dupes\n",
    "df_sub1_short = df_sub1_long.drop_duplicates()\n",
    "df_sub2_short = df_sub2_long.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5b4a4400",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "size of eli5 data w/o dupes:  (6966, 6)\n",
      "size of nsq w/o dupes:  (6140, 6)\n",
      "total rows:  13106\n"
     ]
    }
   ],
   "source": [
    "print(\"size of eli5 data w/o dupes: \",df_sub1_short.shape)\n",
    "print(\"size of nsq w/o dupes: \",df_sub2_short.shape)\n",
    "\n",
    "print(\"total no-dupe rows: \", df_sub1_short.shape[0]+df_sub2_short.shape[0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5f496f8",
   "metadata": {},
   "source": [
    "**info:** I have 13106 total non-dupe rows/posts over both together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "89a0e77f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#3.7 - write each trimmed DF to a csv, just for backups, pre-join\n",
    "df_sub1_short.to_csv(mypath+'sub1_nodupe.csv')\n",
    "df_sub2_short.to_csv(mypath+'sub2_nodupe.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "3355154f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #I discovered an extra erroneous column in this output data, \n",
    "# #so I'm removing that. It might be recreated if I rerun anything.\n",
    "# #currently, this cell doesn't need rerunning\n",
    "# #df_sub1_short.columns\n",
    "#     # lisapaul@malumeum code $grep Unnamed ../data/*.csv\n",
    "#     # ../data/sub1_nodupe.csv:,Unnamed: 0,created_utc,title,self_text,subreddit,Unnamed: 0.1\n",
    "#     # ../data/sub2_nodupe.csv:,Unnamed: 0,created_utc,title,self_text,subreddit,Unnamed: 0.1\n",
    "# df_sub1_short.drop(columns=['Unnamed: 0.1'], inplace=True)\n",
    "# df_sub2_short.drop(columns=['Unnamed: 0.1'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "1a74b6a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'created_utc', 'title', 'self_text', 'subreddit'], dtype='object')"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sub1_short.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "a581a8e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/3n/chlf84kj2yzdb249ph24n5tm0000gn/T/ipykernel_1112/189018337.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_sub1_short['is_eli5'] = None\n",
      "/var/folders/3n/chlf84kj2yzdb249ph24n5tm0000gn/T/ipykernel_1112/189018337.py:18: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_sub2_short['is_eli5'] = None\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>created_utc</th>\n",
       "      <th>title</th>\n",
       "      <th>self_text</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>is_eli5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1.697460e+09</td>\n",
       "      <td>How do people make memes like this?</td>\n",
       "      <td>https://reddit.com/r/shitposting/s/8YOkZrYh5d ...</td>\n",
       "      <td>NoStupidQuestions</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1.697460e+09</td>\n",
       "      <td>Why do so many people freak out at the airport...</td>\n",
       "      <td>I feel like almost every day I see a video of ...</td>\n",
       "      <td>NoStupidQuestions</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0   created_utc  \\\n",
       "0           1  1.697460e+09   \n",
       "1           2  1.697460e+09   \n",
       "\n",
       "                                               title  \\\n",
       "0                How do people make memes like this?   \n",
       "1  Why do so many people freak out at the airport...   \n",
       "\n",
       "                                           self_text          subreddit  \\\n",
       "0  https://reddit.com/r/shitposting/s/8YOkZrYh5d ...  NoStupidQuestions   \n",
       "1  I feel like almost every day I see a video of ...  NoStupidQuestions   \n",
       "\n",
       "  is_eli5  \n",
       "0       0  \n",
       "1       0  "
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#3.8\n",
    "#column name planning for after joined, double-tall DF\n",
    "\n",
    "#this is just because I ran a couple things out of order once\n",
    "df_sub1_short.drop(columns=['is_eli5'], inplace=True)\n",
    "df_sub2_short.drop(columns=['is_eli5'], inplace=True)\n",
    "\n",
    "\n",
    "#attrib nolan: concat through same cols\n",
    "#& reminder why/how, attrib Juston\n",
    "#Yes combine in same cols (not double wide DF), BUT WITH just one extra col, binarized for which subreddit\n",
    "\n",
    "#first attempt\n",
    "#df_sub1_short['is_eli5'] = 1\n",
    "#rewritten, attrib ChatGPT, due to SettingWithCopyWarning\n",
    "\n",
    "df_sub1_short['is_eli5'] = None\n",
    "df_sub1_short.loc[:, 'is_eli5'] = 1\n",
    "\n",
    "df_sub1_short.columns\n",
    "#df_sub1_short.head()\n",
    "\n",
    "df_sub2_short['is_eli5'] = None\n",
    "df_sub2_short.loc[:, 'is_eli5'] = 0\n",
    "\n",
    "df_sub2_short.columns\n",
    "#df_sub2_short.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "f6f9075c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>created_utc</th>\n",
       "      <th>title</th>\n",
       "      <th>self_text</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>is_eli5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1.697390e+09</td>\n",
       "      <td>eli5 could people from the last century compre...</td>\n",
       "      <td>Lets say someone in 1990 plays some Super Mari...</td>\n",
       "      <td>explainlikeimfive</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1.697390e+09</td>\n",
       "      <td>Eli5 Home EV charging</td>\n",
       "      <td>Don’t know anything about EV charging\\n\\nWhat ...</td>\n",
       "      <td>explainlikeimfive</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1.697390e+09</td>\n",
       "      <td>ELI5: why are we potentially able to hold our ...</td>\n",
       "      <td>I understand that it's the lack of oxygen that...</td>\n",
       "      <td>explainlikeimfive</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1.697389e+09</td>\n",
       "      <td>ELI5: Acquiring my car’s title registration?</td>\n",
       "      <td>Hey everyone, first time truly posting so bear...</td>\n",
       "      <td>explainlikeimfive</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1.697389e+09</td>\n",
       "      <td>eli5- engine &amp; cabin air filters</td>\n",
       "      <td>ELI5 - why does the auto mechanic always try t...</td>\n",
       "      <td>explainlikeimfive</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0   created_utc  \\\n",
       "0           0  1.697390e+09   \n",
       "1           1  1.697390e+09   \n",
       "2           2  1.697390e+09   \n",
       "3           3  1.697389e+09   \n",
       "4           4  1.697389e+09   \n",
       "\n",
       "                                               title  \\\n",
       "0  eli5 could people from the last century compre...   \n",
       "1                              Eli5 Home EV charging   \n",
       "2  ELI5: why are we potentially able to hold our ...   \n",
       "3       ELI5: Acquiring my car’s title registration?   \n",
       "4                   eli5- engine & cabin air filters   \n",
       "\n",
       "                                           self_text          subreddit  \\\n",
       "0  Lets say someone in 1990 plays some Super Mari...  explainlikeimfive   \n",
       "1  Don’t know anything about EV charging\\n\\nWhat ...  explainlikeimfive   \n",
       "2  I understand that it's the lack of oxygen that...  explainlikeimfive   \n",
       "3  Hey everyone, first time truly posting so bear...  explainlikeimfive   \n",
       "4  ELI5 - why does the auto mechanic always try t...  explainlikeimfive   \n",
       "\n",
       "  is_eli5  \n",
       "0       1  \n",
       "1       1  \n",
       "2       1  \n",
       "3       1  \n",
       "4       1  "
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#4 join both subreddits' DFs, \n",
    "    \n",
    "#attrib: Kiersten\n",
    "    #axis 0 = stack //vertically//\n",
    "df_both_subs = pd.concat([df_sub1_short, df_sub2_short], axis = 0)\n",
    "\n",
    "\n",
    "\n",
    "df_both_subs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "ee5214c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#4.9 - write the combo DF to a csv, just in case\n",
    "df_both_subs.to_csv(mypath+'both_subs.csv')\n",
    "\n",
    "#length of new file seems correct\n",
    "# -rw-r--r--   1 lisapaul  staff  2910337 Oct 19 21:17 sub1_nodupe.csv\n",
    "# -rw-r--r--   1 lisapaul  staff  3200120 Oct 19 21:17 sub2_nodupe.csv\n",
    "# drwxr-xr-x  22 lisapaul  staff      704 Oct 19 21:28 .\n",
    "# -rw-r--r--   1 lisapaul  staff  6124339 Oct 19 21:28 both_subs.csv\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a37a4b1",
   "metadata": {},
   "source": [
    "### Here ends this notebook"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
