{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "930218a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import numpy as np #tim always does (for .arange() ??)\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "\n",
    "from os import listdir\n",
    "from os.path import isfile, join"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6a3e56be-a4bf-43d4-8c57-7f9954b44b46",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#I already did my pulls via the other script, \n",
    "    #insert filepath of script here ####attrib for grepping\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90c4c84c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#for future reference, here are my subreddits:\n",
    "#sub1reddit = reddit.subreddit('explainlikeimfive')\n",
    "#sub2reddit = reddit.subreddit('nostupidquestions')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "103d7151-cf2e-47cb-82c2-578faa763888",
   "metadata": {},
   "outputs": [],
   "source": [
    "#2 - \n",
    "#read in *.csv PER SUBREDDIT, to get 2 separate ENORMOUS DFs (1 per subr)\n",
    "\n",
    "mypath = \"../data/\"\n",
    "many_files = [mypath+f for f in listdir(mypath) if isfile(join(mypath, f))]\n",
    "    #attrib\n",
    "    #https://stackoverflow.com/questions/3207219/how-do-i-list-all-files-of-a-directory\n",
    "\n",
    "#read in & create dirty dataframe for sub1\n",
    "sub1_files = [g for g in many_files if \"sub1\" in g]\n",
    "for file in sub1_files:\n",
    "    #attrib\n",
    "    #https://mungingdata.com/pandas/read-multiple-csv-pandas-dataframe/\n",
    "    df_sub1_long = pd.concat((pd.read_csv(i) for i in sub1_files))        \n",
    "   \n",
    "#read in & create dirty dataframe for sub1 \n",
    "sub2_files = [h for h in many_files if \"sub2\" in h]\n",
    "for file in sub2_files:\n",
    "    #attrib\n",
    "    #https://mungingdata.com/pandas/read-multiple-csv-pandas-dataframe/\n",
    "    df_sub2_long = pd.concat((pd.read_csv(j) for j in sub2_files))        \n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "ea22a4f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>created_utc</th>\n",
       "      <th>title</th>\n",
       "      <th>self_text</th>\n",
       "      <th>subreddit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1.697390e+09</td>\n",
       "      <td>eli5 could people from the last century compre...</td>\n",
       "      <td>Lets say someone in 1990 plays some Super Mari...</td>\n",
       "      <td>explainlikeimfive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1.697390e+09</td>\n",
       "      <td>Eli5 Home EV charging</td>\n",
       "      <td>Don’t know anything about EV charging\\n\\nWhat ...</td>\n",
       "      <td>explainlikeimfive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1.697390e+09</td>\n",
       "      <td>ELI5: why are we potentially able to hold our ...</td>\n",
       "      <td>I understand that it's the lack of oxygen that...</td>\n",
       "      <td>explainlikeimfive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1.697389e+09</td>\n",
       "      <td>ELI5: Acquiring my car’s title registration?</td>\n",
       "      <td>Hey everyone, first time truly posting so bear...</td>\n",
       "      <td>explainlikeimfive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1.697389e+09</td>\n",
       "      <td>eli5- engine &amp; cabin air filters</td>\n",
       "      <td>ELI5 - why does the auto mechanic always try t...</td>\n",
       "      <td>explainlikeimfive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0   created_utc  \\\n",
       "0           0  1.697390e+09   \n",
       "1           1  1.697390e+09   \n",
       "2           2  1.697390e+09   \n",
       "3           3  1.697389e+09   \n",
       "4           4  1.697389e+09   \n",
       "\n",
       "                                               title  \\\n",
       "0  eli5 could people from the last century compre...   \n",
       "1                              Eli5 Home EV charging   \n",
       "2  ELI5: why are we potentially able to hold our ...   \n",
       "3       ELI5: Acquiring my car’s title registration?   \n",
       "4                   eli5- engine & cabin air filters   \n",
       "\n",
       "                                           self_text          subreddit  \n",
       "0  Lets say someone in 1990 plays some Super Mari...  explainlikeimfive  \n",
       "1  Don’t know anything about EV charging\\n\\nWhat ...  explainlikeimfive  \n",
       "2  I understand that it's the lack of oxygen that...  explainlikeimfive  \n",
       "3  Hey everyone, first time truly posting so bear...  explainlikeimfive  \n",
       "4  ELI5 - why does the auto mechanic always try t...  explainlikeimfive  "
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sub1_long.shape\n",
    "df_sub1_long.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "fe710c91",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3835, 5)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sub2_long.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "a9197060",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7479, 5)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#3.0 - remove the empty posts, just in case they sneaked in thru the pull's culling\n",
    "df_sub1_long = df_sub1_long[ df_sub1_long['self_text'] != '']\n",
    "df_sub2_long = df_sub2_long[ df_sub2_long['self_text'] != '']\n",
    "#which they didn't\n",
    "df_sub1_long.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "3df8cd87",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3835, 5)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sub2_long.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "f7f33e1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#3.1 remove duplicates from both subreddits' data\n",
    "    #- TIP: You can use the created_utc attribute of a post to keep track of the timestamp and ensure non-overlapping pulls. The created_utc attribute represents the post's creation time in UTC.\n",
    "    #info this may have saved me the de-duping work\n",
    "\n",
    "\n",
    "#attrib: Rafi for syntax of dropping dupes\n",
    "df_sub1_short = df_sub1_long.drop_duplicates()\n",
    "df_sub2_short = df_sub2_long.drop_duplicates()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "5b4a4400",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6553"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sub1_short.shape[0]+df_sub2_short.shape[0]\n",
    "#info: I have 6553 total non-dupe rows/posts over both together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "3355154f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#3.7 - write each trimmed DF to a csv, just for backups pre join\n",
    "df_sub1_short.to_csv(mypath+'sub1_nodupe.csv')\n",
    "df_sub2_short.to_csv(mypath+'sub2_nodupe.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a581a8e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#3.8\n",
    "#column name planning for after joined\n",
    "\n",
    "#per nolan, concat through same cols\n",
    "#reminder why/how per attrib Juston\n",
    "#Yes combine in same cols (not double wide DF), BUT WITH EXTRA ONE binar'd for hwich tehy are\n",
    "    \n",
    "    \n",
    "    \n",
    "#reify this code:\n",
    "\n",
    "#for all in df_sub1_short, new column \"is_sub1\" = 1\n",
    "#for all in df_sub2_short, new column \"is_sub1\" = 0\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6f9075c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#4 join both subreddits' DFs, \n",
    "    \n",
    "#attrib: Kiersten\n",
    "    #axis 0 = stack vertically\n",
    "\n",
    "#combo = pd.concat([df1, df2], axis = 0)\n",
    "    \n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee5214c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#4.9 - write the combo DF to a csv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2eb4c19d-f9d9-4be8-9ca5-5ecbbde48970",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09636020",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67297667",
   "metadata": {},
   "outputs": [],
   "source": [
    "#5 EDA per tutorial\n",
    "#TODO Once you have at least 1000 posts from each subreddit\n",
    "#, you can do some EDA \n",
    "#5.1 perhaps maybe the most common words in each subreddit..?\n",
    "    #see the NLP lesson &/or lab\n",
    "#\n",
    "#5.2 look for patterns \n",
    "    #compare the most-common from each\n",
    "    #least-common?\n",
    "    #length of title?\n",
    "    #length of post?\n",
    "        #can't do, didn't pull - #any particular usernames repeated?\n",
    "#5.2.1 - pairplot? (is that seaborn only?)\n",
    "    #google this, but also .histo the common words \n",
    "        #per sub but also for both\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "851586d1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ced0dbf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "393eff1f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d20b2de",
   "metadata": {},
   "outputs": [],
   "source": [
    "########## more to do ##########"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45eb4a8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#README.md"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57bbef9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ppt - \n",
    "    #make this early on Wednesday? 1st thing Thursday night?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2bcc636",
   "metadata": {},
   "outputs": [],
   "source": [
    "#prob stmt thoughts:\n",
    "    #attrib Katie:\n",
    "    #goal: doesn't have to be online/marketing\n",
    "    #instead, could be email redirects to diff depts w/in company\n",
    "    #eg library reference depts, or the equiv. of same but chatAI avatars\n",
    "    #\n",
    "    #even, we could just say \"look, here's a model, I can do it\"\n",
    "        #for somebody who wants any modeling later\n",
    "        #it is proof of concept, just not within same knowledge domain\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91e3a7b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#todo - rename / make new notebook(s)\n",
    "#todo - last - save to script"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
